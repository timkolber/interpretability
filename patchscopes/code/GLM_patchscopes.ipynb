{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMJYfysaREkb"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mdEmY4rDQ3ik",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Scienfitic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Visuals\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context=\"notebook\",\n",
    "        rc={\"font.size\":16,\n",
    "            \"axes.titlesize\":16,\n",
    "            \"axes.labelsize\":16,\n",
    "            \"xtick.labelsize\": 16.0,\n",
    "            \"ytick.labelsize\": 16.0,\n",
    "            \"legend.fontsize\": 16.0})\n",
    "palette_ = sns.color_palette(\"Set1\")\n",
    "palette = palette_[2:5] + palette_[7:]\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Utilities\n",
    "\n",
    "from general_utils import (\n",
    "  ModelAndTokenizer,\n",
    "  make_inputs,\n",
    "  decode_tokens,\n",
    "  find_token_range,\n",
    "  predict_from_input,\n",
    ")\n",
    "\n",
    "from patchscopes_utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LQX9Qx6GGdLZ"
   },
   "outputs": [],
   "source": [
    "model_to_hook = {\n",
    "    \"EleutherAI/pythia-12b\": set_hs_patch_hooks_neox,\n",
    "    \"meta-llama/Llama-2-13b-hf\": set_hs_patch_hooks_llama,\n",
    "    \"lmsys/vicuna-7b-v1.5\": set_hs_patch_hooks_llama,\n",
    "    \"./stable-vicuna-13b\": set_hs_patch_hooks_llama,\n",
    "    \"CarperAI/stable-vicuna-13b-delta\": set_hs_patch_hooks_llama,\n",
    "    \"EleutherAI/gpt-j-6b\": set_hs_patch_hooks_gptj,\n",
    "    \"t5-large\": set_hs_patch_hooks_t5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set Hugging Face cache directory\n",
    "os.environ[\"HF_HOME\"] = \"/home/students/kolber/seminars/kolber/.cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "4479f16b9a544b79bb8790693701d8de",
      "708c70001ba64b3196bf2ced4fe01f6c"
     ]
    },
    "id": "fKGGJO3GQ3in",
    "outputId": "aed82adb-d542-4de6-ade7-c2a4f7aadcc6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/kolber/miniconda3/envs/GLM/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "\n",
    "model_name = \"t5-large\"\n",
    "sos_tok = False\n",
    "\n",
    "if \"13b\" in model_name or \"12b\" in model_name:\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    torch_dtype = None\n",
    "\n",
    "mt = ModelAndTokenizer(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=False,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "mt.set_hs_patch_hooks = model_to_hook[model_name]\n",
    "mt.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsZLB6l_GdLa"
   },
   "source": [
    "# Next token prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yuKvnceYGdLe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/48 [00:00<00:16,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [(16, tensor([-31.5204, -24.7124,  -8.5381,  ...,   3.9018,   9.3325,   8.8674]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/48 [00:00<00:15,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [(16, tensor([-34.5127, -27.2876, -14.7393,  ...,   1.2115,   7.2054,  14.3314]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 3/48 [00:01<00:14,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: [(16, tensor([-46.8915, -38.2838, -22.7533,  ...,   7.5503,  -0.1532,  11.1236]))]}\n",
      "{3: [(16, tensor([-50.6588, -32.5149, -25.5325,  ...,  16.9417,  -4.7222,   4.0549]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/48 [00:01<00:15,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: [(16, tensor([-53.2100, -23.9260, -23.2108,  ...,  25.0026,  -8.9490,  -6.5479]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 6/48 [00:02<00:16,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: [(16, tensor([-65.9908, -32.8220, -19.4189,  ...,  25.7656, -18.4125,   2.1450]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 7/48 [00:02<00:15,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6: [(16, tensor([-78.4446, -39.7274, -23.4656,  ...,  14.3850, -16.6949,   4.3686]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 8/48 [00:02<00:14,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{7: [(16, tensor([-84.2563, -38.9248, -24.7010,  ...,  15.4495, -24.3100,  11.0296]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 9/48 [00:03<00:14,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8: [(16, tensor([-87.1161, -47.6444, -12.1023,  ...,   6.8382, -25.1064,   8.5141]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 10/48 [00:03<00:13,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{9: [(16, tensor([-89.1746, -54.4318, -14.1479,  ...,   2.2850, -24.7855,   1.8542]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 11/48 [00:04<00:13,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{10: [(16, tensor([-90.8992, -50.9091, -17.0864,  ...,   3.5605,  -6.1756,  -6.5574]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 12/48 [00:04<00:12,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{11: [(16, tensor([-96.5470, -51.3193, -22.5191,  ...,  18.8353,  -6.5922,   6.5929]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 13/48 [00:04<00:12,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12: [(16, tensor([-131.2078,  -49.2928,  -24.3215,  ...,    7.8943,  -16.3852,\n",
      "          -7.8061]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 14/48 [00:05<00:11,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{13: [(16, tensor([-137.6351,  -44.4710,  -39.4885,  ...,    7.8692,  -29.5968,\n",
      "          -5.0435]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 15/48 [00:05<00:11,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{14: [(16, tensor([-145.2646,  -41.5266,  -40.0572,  ...,    7.7690,  -63.4637,\n",
      "          20.1157]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 16/48 [00:05<00:10,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{15: [(16, tensor([-192.9487,  -27.7642,  -36.2089,  ...,    2.3843,  -59.5213,\n",
      "          26.9575]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 17/48 [00:06<00:10,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{16: [(16, tensor([-238.9390,  -15.8331,  -34.5819,  ...,   21.6181, -110.2432,\n",
      "          22.6856]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 18/48 [00:06<00:10,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17: [(16, tensor([-254.4924,  -15.3350,  -35.6611,  ...,   13.9891,  -97.6739,\n",
      "          39.7461]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 19/48 [00:06<00:09,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{18: [(16, tensor([-265.1894,  -39.4576,  -39.2520,  ...,   32.6542, -112.9305,\n",
      "          26.1969]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 20/48 [00:07<00:09,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{19: [(16, tensor([-305.1680,  -20.9698,  -23.1064,  ...,   71.0054, -116.6115,\n",
      "          26.1271]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 21/48 [00:07<00:09,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{20: [(16, tensor([-382.3799,  -24.9211,  -29.5748,  ...,   60.5485,  -84.3818,\n",
      "          58.1346]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 22/48 [00:07<00:08,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{21: [(16, tensor([-389.5952,  -30.1340,  -18.8953,  ...,   56.0900,  -64.6374,\n",
      "          78.8082]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 23/48 [00:08<00:08,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{22: [(16, tensor([-335.1400,  -73.0103,   -9.0969,  ...,   -7.2111,  -40.2585,\n",
      "         166.1876]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 24/48 [00:08<00:08,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{23: [(16, tensor([-0.2790, -0.1066, -0.0705,  ..., -0.0529, -0.1366,  0.2305]))]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 24/48 [00:08<00:08,  2.80it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     prompt_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho is Obama?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m     position_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 12\u001b[0m     prec_1, surprisal \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_patch_next_token_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_target\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     records\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m: layer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprec_1\u001b[39m\u001b[38;5;124m'\u001b[39m: prec_1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurprisal\u001b[39m\u001b[38;5;124m'\u001b[39m: surprisal})\n\u001b[1;32m     19\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(records)\n",
      "File \u001b[0;32m/mnt/proj/kolber/interpretability/patchscopes/code/patchscopes_utils.py:641\u001b[0m, in \u001b[0;36mevaluate_patch_next_token_prediction\u001b[0;34m(mt, prompt_source, prompt_target, layer_source, layer_target, position_source, position_target, module, position_prediction, transform)\u001b[0m\n\u001b[1;32m    639\u001b[0m _, answer_t_orig \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(dist_orig, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(mt\u001b[38;5;241m.\u001b[39mmodel) \u001b[38;5;241m==\u001b[39m T5ForConditionalGeneration:\n\u001b[0;32m--> 641\u001b[0m     hidden_rep \u001b[38;5;241m=\u001b[39m \u001b[43moutput_orig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoder_hidden_states\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_source\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\n\u001b[1;32m    642\u001b[0m         position_source\n\u001b[1;32m    643\u001b[0m     ]\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    645\u001b[0m     hidden_rep \u001b[38;5;241m=\u001b[39m output_orig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m][layer_source \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m][position_source]\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Evaluate the ID prompt on the validation set of WikiText (with/without mappings)\n",
    "\n",
    "device = mt.model.device\n",
    "\n",
    "prompt_target = \"cat -> cat\\n1135 -> 1135\\nhello -> hello\\n?\"\n",
    "position_target = -1\n",
    "\n",
    "records = []\n",
    "for layer in tqdm(range(mt.num_layers)): \n",
    "    prompt_source = \"Who is Obama?\"\n",
    "    position_source = 2\n",
    "    prec_1, surprisal = evaluate_patch_next_token_prediction(\n",
    "        mt, prompt_source, prompt_target, layer, layer,\n",
    "        position_source, position_target, position_prediction=position_target\n",
    "        )\n",
    "\n",
    "    records.append({'layer': layer, 'prec_1': prec_1, 'surprisal': surprisal})\n",
    "\n",
    "results = pd.DataFrame.from_records(records)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
